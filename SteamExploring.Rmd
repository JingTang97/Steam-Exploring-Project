---
title: "Steam Exploring Project"
author: "Mira Tang"
date: "12/10/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("ggplot2", "knitr", "arm", "data.table", "foreign", "car", "faraway", "nnet", "reshape2", "VGAM", "jsonlite", "mongolite", "lubridate", "tidyverse", "stringr", "rvest", "RCurl", "XML", "htm2txt", "dplyr", "tidytext", "tidyr", "scales", "wordcloud", "rstanarm", "glmmADMB", "kableExtra", "utils", "leaflet", "sp", "magrittr", "maps", "htmltools", "rgdal", "maptools", "readr", "rgeos", "rmapshaper", "ggmap", "ggrepel", "RCurl", "Cairo", "readxl", "stringr", "esquisse", "expss","kableExtra", update = FALSE)
```

# Scrap Raw Data
```{r, eval = FALSE}
## ATTENTION: The following code may change through seconds. In order to keep the reproducibility of this project, saving all data as csv files.

# Scraping the data of current players from Steam Charts
## Specifying the url
url <- "https://store.steampowered.com/stats/"
## Reading the HTML
webpage <- read_html(url)
currentplayers_1 <- html_nodes(webpage, "td:nth-child(1) .currentServers")
currentplayers_1 <- html_text(currentplayers_1)
currentplayers_1 <- gsub(",","",currentplayers_1)
currentplayers_1 <- as.data.frame(as.numeric(currentplayers_1))

currentplayers_2 <- html_nodes(webpage, "td+ td .currentServers")
currentplayers_2 <- html_text(currentplayers_2)
currentplayers_2 <- gsub(",","",currentplayers_2)
currentplayers_2 <- as.data.frame(as.numeric(currentplayers_2))

currentplayers_3 <- html_nodes(webpage, ".gameLink")
currentplayers_3 <- html_text(currentplayers_3)
currentplayers_3 <- as.data.frame(currentplayers_3)

currentplayers <- cbind(currentplayers_3, currentplayers_1, currentplayers_2)
rm(currentplayers_1, currentplayers_2, currentplayers_3)
## Change the names of variables
colnames(currentplayers) <- c("Game", "Current.Players", "Peak.Today")
## Save data
write.csv(currentplayers, file = "Raw-Data/currentplayers.csv")
rm(url, wrbpage, currentplayers)

# Scraping the appid from SteamDB
left <- "https://steamdb.info/apps/page"
page <- 1:1400
url <- str_c(left, page, "/")

get_appid <- function(html) {
  # given a html of the season, return sub urls of per event
  appid <- html %>%
    html_nodes(".applogo+ td a") %>%
    html_text()
  return(appid)
}

get_name <- function(html) {
  # given a html of the season, return sub urls of per event
  name <- html %>%
    html_nodes(".muted , .b") %>%
    html_text()
  return(name)
}

AppID <- data.frame()
Sys.time()
for (i in 1:length(url)) {
  html <- read_html(url[i])
  appid[(1 + 80*(i-1)):(80 + 80*(i-1))] <- get_appid(html)
  name[(1 + 80*(i-1)):(80 + 80*(i-1))] <- get_name(html)
}
Sys.time()
AppID <- as.data.frame(cbind(appid, name))
## Save data
write.csv(AppID, file = "Raw-Data/AppID.csv")

# Scraping the data of each app from Steam using appid
Current_players <- read.csv("Raw-Data/currentplayers.csv")
Current_players_top30 <- Current_players[1:30,]
## In order to keep the accuracy of following scraping, manually input the appid of top30
Current_players_top30$AppID <- c(578080,570,730,359550,359550,230410,238960,582010,440,622590,
                           582010,346110,252950,8930,289070,755790,281990,4000,872790,381210,
                           105600,218620,377160,304930,594570,841370,221100,251570,812140,413150)

left <- "https://store.steampowered.com/app/"
id <- Current_players_top30$AppID
url <- str_c(left, id, "/")

get_genre <- function(html) {
  # given a html of the season, return sub urls of per event
  Genre <- html %>%
    html_nodes(".details_block:nth-child(1) > a") %>%
    html_text()
  return(Genre)
}

get_developer <- function(html) {
  # given a html of the season, return sub urls of per event
 Developer <- html %>%
    html_nodes("br+ .dev_row a") %>%
    html_text()
  return(Developer)
}

Info <- data.frame()
Sys.time()
for (i in 1:1) {
  html <- read_html(url[i])
  Genre[i] <- get_genre(html)
  Developer[i] <- get_developer(html)
}
Sys.time()
AppID <- as.data.frame(cbind(appid, name))
```

# Import datasets
```{r}
Steam_sales <- read.csv("Raw-Data/Steam sales.csv")
Steam_playtime <- read.csv("Raw-Data/Steam top by playtime.csv")
Current_players <- read.csv("Raw-Data/currentplayers.csv")
#AppID <- read.csv("Raw-Data/AppID.csv")
```

# Data Cleaning
```{r}
colnames(Steam_sales)[1] <- "Sales.rank"
colnames(Steam_playtime)[1] <- "Playtime.rank"
colnames(Current_players)[1] <- "CurrentPlayers.rank"

Steam <- merge(Steam_playtime, Steam_sales, by = "Game")
Steam <- merge(Steam, Current_players, by = "Game")

#AppID <- AppID[,-1]
#colnames(AppID) <- c("AppID", "Game")
#Steam <- merge(Steam, AppID, by = "Game")

```

# EDA
```{r}

```

# Benford Analysis
```{r}

```

# Text Mining
```{r}

```

# Shiny apps
```{r}

```

