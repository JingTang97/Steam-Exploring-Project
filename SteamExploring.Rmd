---
title: "Steam Exploring Project"
author: "Mira Tang"
date: "12/10/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("ggplot2", "knitr", "arm", "data.table", "foreign", "car", "faraway", "nnet", "reshape2", "VGAM", "jsonlite", "mongolite", "lubridate", "tidyverse", "stringr", "rvest", "RCurl", "XML", "htm2txt", "dplyr", "tidytext", "tidyr", "scales", "wordcloud", "rstanarm", "glmmADMB", "kableExtra", "utils", "leaflet", "sp", "magrittr", "maps", "htmltools", "rgdal", "maptools", "readr", "rgeos", "rmapshaper", "ggmap", "ggrepel", "RCurl", "Cairo", "readxl", "stringr", "esquisse", "expss","kableExtra", "reshape2", "benford.analysis", "magrittr", update = FALSE)
```

# Data Pre-processing
## Scraping Raw Data
```{r, eval = FALSE}
## ATTENTION: The result of following code may change through seconds. In order to keep the reproducibility of this project, saving all data as csv files.

# Scraping the data of current players from Steam Charts
## Specifying the url
url <- "https://store.steampowered.com/stats/"
## Reading the HTML
webpage <- read_html(url)
currentplayers_1 <- html_nodes(webpage, "td:nth-child(1) .currentServers")
currentplayers_1 <- html_text(currentplayers_1)
currentplayers_1 <- gsub(",", "", currentplayers_1)
currentplayers_1 <- as.data.frame(as.numeric(currentplayers_1))

currentplayers_2 <- html_nodes(webpage, "td+ td .currentServers")
currentplayers_2 <- html_text(currentplayers_2)
currentplayers_2 <- gsub(",", "", currentplayers_2)
currentplayers_2 <- as.data.frame(as.numeric(currentplayers_2))

currentplayers_3 <- html_nodes(webpage, ".gameLink")
currentplayers_3 <- html_text(currentplayers_3)
currentplayers_3 <- as.data.frame(currentplayers_3)

currentplayers <- cbind(currentplayers_3, currentplayers_1, currentplayers_2)
rm(currentplayers_1, currentplayers_2, currentplayers_3)
## Change the names of variables
colnames(currentplayers) <- c("Game", "Current.Players", "Peak.Today")
## Save data
write.csv(currentplayers, file = "Raw-Data/currentplayers.csv")
rm(url, wrbpage, currentplayers)

# Scraping the appid from SteamDB
left <- "https://steamdb.info/apps/page"
page <- 1:1400
url <- str_c(left, page, "/")

get_appid <- function(html) {
  appid <- html %>%
    html_nodes(".applogo+ td a") %>%
    html_text()
  return(appid)
}

get_name <- function(html) {
  name <- html %>%
    html_nodes(".muted , .b") %>%
    html_text()
  return(name)
}

AppID <- data.frame()
Sys.time()
for (i in 1:length(url)) {
  html <- read_html(url[i])
  appid[(1 + 80 * (i - 1)):(80 + 80 * (i - 1))] <- get_appid(html)
  name[(1 + 80 * (i - 1)):(80 + 80 * (i - 1))] <- get_name(html)
}
Sys.time()
AppID <- as.data.frame(cbind(appid, name))
## Save data
write.csv(AppID, file = "Raw-Data/AppID.csv")

# Scraping the price data of each app from SteamDB
Current_players <- read.csv("Raw-Data/currentplayers.csv")
Current_players_top30 <- Current_players[1:30, ]
## In order to keep the accuracy of following scraping, manually input the appid of top30
Current_players_top30$AppID <- c(
  578080, 570, 730, 359550, 359550, 230410, 238960, 582010, 440, 622590,
  582010, 346110, 252950, 8930, 289070, 755790, 281990, 4000, 872790, 381210,
  105600, 218620, 377160, 304930, 594570, 841370, 221100, 251570, 812140, 413150
)

url <- "https://store.steampowered.com/app/578080/"

get_currency <- function(html) {
  Currency <- html %>%
    html_nodes(".price-line") %>%
    html_text()
  return(Currency)
}

get_currentprice <- function(html) {
  CurrentPrice <- html %>%
    html_nodes(".price-line+ td") %>%
    html_text()
  return(CurrentPrice)
}

get_covtertedprice <- function(html) {
  CovtertedPrice <- html %>%
    html_nodes("td.table-prices-converted:nth-child(3)") %>%
    html_text()
  return(CurrentPrice)
}

get_compare <- function(html) {
  Compare <- html %>%
    html_nodes(".table-prices-converted+ .table-prices-converted") %>%
    html_text()
  return(CurrentPrice)
}

get_lowestrecordedprice <- function(html) {
  LowestRecordedPrice <- html %>%
    html_nodes(".price-discount-minor+ td , .owned+ tr .table-prices-converted+ td , .text-center+ td , .price-discount+ td , .price-discount-major+ td") %>%
    html_text()
  return(LowestRecordedPrice)
}

url <- "https://steamdb.info/app/578080/"
html <- read_html(url)

Currency <- html_text(html_nodes(html, ".price-line"))

CurrentPrice <- html_text(html_nodes(html, ".price-line+ td"))

ConvtertedPrice_raw <- html_text(html_nodes(html, "td.table-prices-converted:nth-child(3)"))
ConvtertedPrice <- NULL
ConvtertedPrice[1] <- CurrentPrice[1]
ConvtertedPrice[2:41] <- ConvtertedPrice_raw[1:40]
rm(ConvtertedPrice_raw)

Compare_raw <- html_text(html_nodes(html, ".table-prices-converted+ .table-prices-converted"))
Compare <- NULL
Compare[c(1, 41)] <- 0
Compare[2:40] <- Compare_raw[1:39]
rm(Compare_raw)

LowestRecordedPrice_raw <- html_text(html_nodes(html, ".price-discount-major+ td , .price-discount+ td , .text-center+ td , .owned+ tr .table-prices-converted+ td , .price-discount-minor+ td"))
LowestRecordedPrice[1] <- LowestRecordedPrice_raw[1]
LowestRecordedPrice[2:40] <- LowestRecordedPrice_raw[3:41]
LowestRecordedPrice[41] <- "$10.49"
rm(LowestRecordedPrice_raw)

StorePrices_PUBG <- data.frame()
StorePrices_PUBG <- as.data.frame(cbind(Currency, CurrentPrice, ConvtertedPrice, Compare, LowestRecordedPrice))
write.csv(StorePrices_PUBG, file = "Raw-Data/StorePrices_PUBG.csv")

# Scraping top10 reviews from top30 games based on play time
# Some games have limitation of age thus can not open the url without logging in
AppID <- c(578080,570,730,359550,230410,238960,582010,440,
           346110,252950,8930,289070,755790,281990,4000,872790,381210,
           105600,218620,377160,304930,594570,841370,221100,251570,812140,413150)

left <- "https://steamcommunity.com/app/"
id <- AppID
url <- str_c(left, id, "/reviews/?browsefilter=toprated&snr=1_5_100010_")

Review <- matrix(nrow = 10, ncol = 27)
for(i in 1:27){
  html <- read_html(url[i])
  Review_html <- html_nodes(html, ".apphub_CardTextContent")
  Review[c(1:length(html_text(Review_html))),i] <-  html_text(Review_html)
}
Review <- as.data.frame(Review)

raw.text <- matrix(" ", nrow =27, ncol = 1) 
for(i in 1:27){
  for(j in 1:10){
    raw.text[i] <- paste(raw.text[i],Review[j,i])
  }
}
raw.text <- as.data.frame(raw.text)
colnames(raw.text) <- "text"
raw.text$text <- as.character(raw.text$text)
write.csv(raw.text, file = "Raw-Data/raw.text.csv")
```

## Import datasets
```{r}
Steam_sales <- read.csv("Raw-Data/Steam sales.csv")
Steam_playtime <- read.csv("Raw-Data/Steam top by playtime.csv")
Current_players <- read.csv("Raw-Data/currentplayers.csv")
StorePrices_PUBG <- read.csv("Raw-Data/StorePrices_PUBG.csv")
raw.text <- read.csv("Raw-Data/raw.text.csv")
```

## Data Cleaning
```{r, warning = FALSE, error = FALSE}
# Steam
colnames(Steam_sales)[1] <- "Sales.rank"
colnames(Steam_playtime)[1] <- "Playtime.rank"
colnames(Current_players)[1] <- "CurrentPlayers.rank"

Steam <- merge(Steam_playtime, Steam_sales, by = "Game")
Steam <- merge(Steam, Current_players, by = "Game")

ScoreRank_raw <- unlist(strsplit(unlist(strsplit(unlist(strsplit(unlist(strsplit(as.character(Steam$Score.rank.Userscore...Metascore.), "[%]")), "[(]")), "[)]")), "[/]"))
ScoreRank_raw <- na.omit(as.data.frame(as.numeric(ScoreRank_raw)))
ScoreRank <- NULL
ScoreRank[c(4 * 3, 16 * 3, 19 * 3, 23 * 3, 34 * 3, 38 * 3, 39 * 3, 44 * 3)] <- NA
ScoreRank[c(1:11, 13:47, 49:56, 58:101, 103:113, 115:116, 118:131)] <- ScoreRank_raw[1:124, 1]

PlayTime <- unlist(strsplit(unlist(strsplit(as.character(Steam$Playtime..Median.), "[(]")), "[)]"))

Discount <- unlist(strsplit(unlist(strsplit(as.character(Steam$Max.discount), "[(]")), "[)]"))

for (i in 1:44) {
  Steam$ScoreRank[i] <- ScoreRank[1 + 3 * (i - 1)]
  Steam$UserScore[i] <- ScoreRank[2 + 3 * (i - 1)]
  Steam$MetaScore[i] <- ScoreRank[3 + 3 * (i - 1)]
  Steam$Playtime.Mean[i] <- PlayTime[1 + 2 * (i - 1)]
  Steam$Playtime.Median[i] <- PlayTime[2 + 2 * (i - 1)]
  Steam$MaxDiscountPercentage[i] <- Discount[1 + 2 * (i - 1)]
  Steam$LowestPrice[i] <- Discount[2 + 2 * (i - 1)]
}

Steam$PlayersPercentage <- as.numeric(gsub("[%]", "", Steam$Players))
Steam$Owners.before <- as.numeric(gsub("[,]", "", Steam$Owners.before))
Steam$Owners.after <- as.numeric(gsub("[,]", "", Steam$Owners.after))
Steam$Sales <- as.numeric(gsub("[,]", "", Steam$Sales))
Steam$IncreasePercentage <- as.numeric(gsub("[%]", "", Steam$Increase))
Steam$Price.y <- as.numeric(gsub("[$]", "", Steam$Price.y))
Steam$MaxDiscountPercentage <- as.numeric(gsub("[%]", "", Steam$MaxDiscountPercentage))
Steam$LowestPrice <- as.numeric(gsub("[$]", "", Steam$LowestPrice))
Steam$Release.date <- as.Date(Steam$Release.date, format = "%b %d,%Y")
Steam$Release.year <- year(Steam$Release.date)
Steam$Release.month <- month(Steam$Release.date)
Steam$Release.day <- day(Steam$Release.date)
Steam$SalesVolume <- round(Steam$Sales/Steam$Price.y)

Steam <- Steam[, c(1, 2, 9, 17, 3, 6, 10:12, 32, 14, 28, 25:26, 18:24, 27, 29:31)]
colnames(Steam) <- c("Game", "Rank of Playtime", "Rank of Sales", "Rank of CurrentPlayers", "Release Date", "Owners Level", "Owners Before", "Owners After", "Sales","Approximately Sales Volume", "Price", "Increase(Percentage)", "Max Discount(Percentage of Original)", "Lowest Price", "Current Players", "Peak Today", "Score Rank(Percentage)", "User Score", "Meta Score", "Average of Playtime", "Median of Playtime", "Actural Players(Percentage)", "Release Year", "Release Month", "Release Day")

# Steam Sales
Steam_sales$Owners.before <- as.numeric(gsub("[,]", "", Steam_sales$Owners.before))
Steam_sales$Owners.after <- as.numeric(gsub("[,]", "", Steam_sales$Owners.after))
Steam_sales$Sales <- as.numeric(gsub("[,]", "", Steam_sales$Sales))
Steam_sales$IncreasePercentage <- as.numeric(gsub("[%]", "", Steam_sales$Increase))
Steam_sales$Price <- as.numeric(gsub("[$]", "", Steam_sales$Price))

Discount <- unlist(strsplit(unlist(strsplit(as.character(Steam_sales$Max.discount), "[(]")), "[)]"))
for (i in 1:9623) {
  Steam_sales$MaxDiscountPercentage[i] <- Discount[1 + 2 * (i - 1)]
  Steam_sales$LowestPrice[i] <- Discount[2 + 2 * (i - 1)]
}
Steam_sales$MaxDiscountPercentage <- as.numeric(gsub("[%]", "", Steam_sales$MaxDiscountPercentage))
Steam_sales$LowestPrice <- as.numeric(gsub("[$]", "", Steam_sales$LowestPrice))

Steam_sales <- Steam_sales[, c(1:5, 7, 10:12)]
colnames(Steam_sales) <- c("Rank of Sales", "Game", "Owners Before", "Owners After", "Sales", "Price", "Increase(Percentage)", "Max Discount(Percentage of Original)", "Lowest Price")
Steam_sales$`Approximately Sales Volume` <- round(Steam_sales$Sales/Steam_sales$Price)

# Store Prices of Game "PUBG"
StorePrices_PUBG$`Converted Price(USD)` <- as.numeric(gsub("[$]", "", StorePrices_PUBG$ConvtertedPrice))
StorePrices_PUBG$`Lowest Recorded Price(USD)` <- as.numeric(gsub("[$]", "", StorePrices_PUBG$LowestRecordedPrice))
StorePrices_PUBG$`Compare Percentage` <- as.numeric(gsub("[%]", "", StorePrices_PUBG$Compare))
StorePrices_PUBG <- StorePrices_PUBG[,-c(1,3:6)]

# Raw Text
raw.text$X <- NULL
raw.text$text <- as.character(raw.text$text)
```

# EDA
```{r}

```

# Benford Analysis
In this part, this project used sales data of games on Steam over past half of year(from Jun 2018 to Dec 2018) for verifing.
```{r}

```

# Text Mining
In text mining, this project choose top 10 reviews of top 30 games based on playing time of each game as representative. Armed at exploring what factors of a game play an important role for users.\par
```{r, error = FALSE, warning = FALSE, message = FALSE, fig.width = 3.5, fig.height = 3.5}
tidy_review <- raw.text %>%
  unnest_tokens(word, text)%>% 
  mutate(word = str_extract(word , "[a-z'\\s]+")) %>%
  anti_join(stop_words, by= "word") %>%
  filter(!word %in% "[\\s]+",
         !word %in% "",
         !word %in% NA,
         !word %in% "Posted",
         !word %in% "posted",
         !word %in% "game")

# Import sentiment dictionaires
bing <- get_sentiments("bing")

sentitext <- raw.text %>%
  unnest_tokens(sentence, text, token = "sentences") %>% 
  ungroup() %>%
  unnest_tokens(word, sentence) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% "[\\s]+",
         !word %in% "",
         !word %in% NA,
         !word %in% "Posted",
         !word %in% "posted",
         !word %in% "game")

bing_counts <- sentitext %>%
  inner_join(bing, by = "word") %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

# Wordclound of all games
tidy_review %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))

# Top 10 Hot Words on Positive and Negative Attitudes
bing_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(
    y = "Contribution to sentiment",
    x = NULL,
    title = "Top 10 Hot Words on Positive and Negative Attitudes"
  ) +
  coord_flip() +
  scale_fill_manual(values=c("#3182bd", "#fa9fb5"))

# Wordclound of Positive and Negative Attitudes
sentitext %>%
  inner_join(bing, by = "word") %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(
    colors = c("#3182bd", "#fa9fb5"),
    max.words = 100
  )
```
\par
From the wordcloud of all reviews, gamers focus more on words like "play", "time", "people" etc., which means what they really matter about a game are how this game preferomed, how many times they devoted in it and how was the entire community of this game. And from the top10 words on negative attitudes, bing dictionary may be not a good choice of sentiment analyzing because there are several words like "killer", "die" are not actually negative emotions when it comes to games. But it still shows that when the users have actual negative emotions about a game are usually because of bugs and other issues of game itself. Vice versa, for positive part, "fun", "free", "pretty" etc. are expected to see.
\par

# Shiny apps
```{r}

```

